{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from scipy.sparse import csr_matrix, coo_matrix\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(433671, 3)\n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv('BX-Book-Ratings.csv', encoding='iso-8859-1', sep = ';')\n",
    "ratings.columns = ['user_id', 'isbn', 'book_rating']\n",
    "books = pd.read_csv('BX-Books.csv', sep=';', encoding = 'iso-8859-1', dtype =str)\n",
    "\n",
    "books[\"Book-Title\"].nunique() == books[\"ISBN\"].nunique()\n",
    "book_dict = books[[\"Book-Title\",\"ISBN\"]].set_index(\"Book-Title\").to_dict()[\"ISBN\"]\n",
    "books['new_isbn'] = books[\"Book-Title\"].apply(lambda x: book_dict[x])\n",
    "books[\"Book-Title\"].nunique() == books[\"new_isbn\"].nunique()\n",
    "books['isbn'] = books['new_isbn']\n",
    "\n",
    "del books['Image-URL-L']\n",
    "del books['Image-URL-M']\n",
    "del books['Image-URL-S']\n",
    "del books['Book-Author']\n",
    "del books['Publisher']\n",
    "del books['ISBN']\n",
    "del books['new_isbn']\n",
    "\n",
    "newdf = ratings[ratings.book_rating>0]\n",
    "joined = books.merge(newdf, on ='isbn')\n",
    "print(newdf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookinfo = pd.read_csv(\"goodreads_list_props.csv\")\n",
    "bookinfo2 = pd.read_csv(\"goodreads_list_props1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "bookinfo3 = pd.read_pickle(\"ibsn_features_full.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['book_name', 'author', 'rating', 'votes', 'description', 'book_type',\n",
       "       'no_of_pages', 'first_published', 'isbn13', 'genre', 'link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookinfo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['book_name', 'author', 'rating', ' votes', ' description', 'book_type',\n",
       "       'no_of_pages', 'first_published', 'isbn13', 'genre', 'link'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookinfo2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['isbn', 'description', 'num_pages', 'title'], dtype='object')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bookinfo3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bookinfo3.columns = ['isbn13','description','no_of_pages','book_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookinfo2.columns = bookinfo.columns\n",
    "bookinfo = pd.concat([bookinfo,bookinfo2])\n",
    "bookinfo = bookinfo[['isbn13','description','no_of_pages','book_name']]\n",
    "bookinfo = pd.concat([bookinfo,bookinfo3])\n",
    "bookinfo.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books.drop_duplicates(subset = 'isbn',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bad ISBN -f\n",
      "Bad ISBN C:\\Users\\vijay\\AppData\\Roaming\\jupyter\\runtime\\kernel-54701759-7a9b-40b3-aed1-ecb74bfa38c3.json\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "def is_isbn10_valid(isbn):\n",
    "    \"\"\"\n",
    "    Check ISBN-10 is valid.\n",
    "    Code Implementaion from:\n",
    "    http://en.wikipedia.org/wiki/International_Standard_Book_Number\n",
    "    \"\"\"\n",
    "    if len(isbn) != 10:\n",
    "        return False\n",
    "    if ((not isbn[0:9].isdigit()) or\n",
    "            ((isbn[-1] != 'X') and (not isbn[-1].isdigit()))):\n",
    "        return False\n",
    "    result = sum((10 - i) * (int(x) if x != 'X' else 10)\n",
    "                 for i, x in enumerate(isbn))\n",
    "    return result % 11 == 0\n",
    "\n",
    "\n",
    "def is_isbn13_valid(isbn):\n",
    "    \"\"\"\n",
    "    Check ISBN-13 is valid.\n",
    "    Code Implemetation from:\n",
    "    http://en.wikipedia.org/wiki/International_Standard_Book_Number\n",
    "    \"\"\"\n",
    "    if len(isbn) != 13 or isbn.isdigit() is not True:\n",
    "        return False\n",
    "    check = (10 - (sum(int(digit) * (3 if idx % 2 else 1)\n",
    "                       for idx, digit in enumerate(isbn[:12])) % 10)) % 10\n",
    "    return check == int(isbn[-1])\n",
    "\n",
    "\n",
    "def isbn13_to_isbn10(isbn13_str):\n",
    "    \"\"\"\n",
    "    Convert ISBN-13 to ISBN-10.\n",
    "    \"\"\"\n",
    "    num = 11 - sum((10 - i) * (int(x))\n",
    "                   for i, x in enumerate(isbn13_str[3:12])) % 11\n",
    "    if num == 10:\n",
    "        check_digit = 'X'\n",
    "    elif num == 11:\n",
    "        check_digit = 0\n",
    "    else:\n",
    "        check_digit = num\n",
    "    return isbn13_str[3:12] + str(check_digit)\n",
    "\n",
    "\n",
    "def isbn10_to_isbn13(isbn10_str):\n",
    "    \"\"\"\n",
    "    Convert ISBN-10 to ISBN-13.\n",
    "    \"\"\"\n",
    "    check_digit = (\n",
    "        10 - (sum(int(digit) * (3 if idx % 2 else 1)\n",
    "                  for idx, digit in enumerate('978' + isbn10_str[:9])\n",
    "                  ) % 10)) % 10\n",
    "    return '978' + isbn10_str[:9] + str(check_digit)\n",
    "\n",
    "\n",
    "def isbn_converter(isbn):\n",
    "    \"\"\"\n",
    "    Convert isbn format to another format.\n",
    "    \"\"\"\n",
    "    if is_isbn10_valid(isbn):\n",
    "        result = isbn10_to_isbn13(isbn)\n",
    "    elif is_isbn13_valid(isbn):\n",
    "        result = isbn13_to_isbn10(isbn)\n",
    "    else:\n",
    "        return None\n",
    "    return result\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for isbn_str in sys.argv[1:]:\n",
    "        the_result = isbn_converter(isbn_str)\n",
    "        if the_result:\n",
    "            print(the_result)\n",
    "        else:\n",
    "            print(\"Bad ISBN \" + isbn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "isbn13 = []\n",
    "for i in books['isbn']:\n",
    "    isbn13.append(isbn_converter(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "books['isbn13'] = isbn13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "books.dropna(subset = ['isbn13'],inplace = True)\n",
    "bookinfo.dropna(subset = ['isbn13'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mergedinfo = bookinfo.merge(books,on = 'isbn13',how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def striphtml(data):\n",
    "    p = re.compile('<.*?>')\n",
    "    try:\n",
    "        return p.sub('', data)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mergedinfo['description'] = mergedinfo['description'].apply(lambda x: striphtml(x))\n",
    "mergedinfo['description'] = mergedinfo['description'].str.strip()\n",
    "mergedinfo['description'] = mergedinfo['description'].str.replace('â€œ','').str.replace(',','').str.replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "# ...\n",
    "filtereddesc = []\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "for desc in mergedinfo['description']:\n",
    "    try:\n",
    "        words = desc.split()\n",
    "        filtereddesc.append([word for word in words if word not in stops])\n",
    "    except:\n",
    "        filtereddesc.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mergedinfo['filtered_description'] = filtereddesc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "wordlist = []\n",
    "for descs in mergedinfo['filtered_description']:\n",
    "    sentence = []\n",
    "    if descs is not None:\n",
    "        for word in descs:\n",
    "            sentence.append(word)\n",
    "    wordlist.append(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download google's word2vec model before running next line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijay\\Anaconda2\\envs\\py35\\lib\\site-packages\\gensim\\utils.py:860: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "genres = ['Science','Satire','Drama','Action','Romance','Mystery','Horror','Travel','Children','Religion','History','Biography','Autobiography','Fantasy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for desc in mergedinfo['filtered_description']:\n",
    "    if desc is not None:\n",
    "        gscore = []\n",
    "        for genre in genres:\n",
    "            simsum = 0\n",
    "            n = 0\n",
    "            for word in desc:\n",
    "                try:\n",
    "                    simsum = simsum + model.similarity(word,genre)\n",
    "                    n = n + 1\n",
    "                except:\n",
    "                    continue\n",
    "            if n!=0:\n",
    "                gscore.append((simsum)/n)\n",
    "            else:\n",
    "                gscore.append(0)\n",
    "        scores.append(gscore)\n",
    "    else:\n",
    "        scores.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "editedscores = []\n",
    "for score in scores:\n",
    "    if score is not None:\n",
    "        editedscores.append(score)\n",
    "    else:\n",
    "        editedscores.append([0] * 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scoredf = pd.DataFrame(editedscores,columns = [genre + '_Score' for genre in genres])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bookfeatures = pd.concat([mergedinfo,scoredf],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AMAZON DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newbooks = pd.read_csv(\"Combine.csv\")\n",
    "newbooksisbn = newbooks['isbn']\n",
    "newbooksisbn13 = []\n",
    "\n",
    "for i in newbooksisbn:\n",
    "    newbooksisbn13.append(isbn_converter(i))\n",
    "\n",
    "newbooksuniqueisbn13 = list(set(newbooksisbn13))\n",
    "amazonbookfeatures = bookinfo[bookinfo['isbn13'].isin(newbooksuniqueisbn13)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijay\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\vijay\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\vijay\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "amazonbookfeatures['description'] = amazonbookfeatures['description'].apply(lambda x: striphtml(x))\n",
    "amazonbookfeatures['description'] = amazonbookfeatures['description'].str.strip()\n",
    "amazonbookfeatures['description'] = amazonbookfeatures['description'].str.replace('â€œ','').str.replace(',','').str.replace('\"','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filtereddesc = []\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "for desc in amazonbookfeatures['description']:\n",
    "    try:\n",
    "        words = desc.split()\n",
    "        filtereddesc.append([word for word in words if word not in stops])\n",
    "    except:\n",
    "        filtereddesc.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijay\\Anaconda2\\envs\\py35\\lib\\site-packages\\ipykernel\\__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "amazonbookfeatures['filtered_description'] = filtereddesc\n",
    "wordlist = []\n",
    "for descs in amazonbookfeatures['filtered_description']:\n",
    "    sentence = []\n",
    "    if descs is not None:\n",
    "        for word in descs:\n",
    "            sentence.append(word)\n",
    "    wordlist.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = []\n",
    "for desc in amazonbookfeatures['filtered_description']:\n",
    "    if desc is not None:\n",
    "        gscore = []\n",
    "        for genre in genres:\n",
    "            simsum = 0\n",
    "            n = 0\n",
    "            for word in desc:\n",
    "                try:\n",
    "                    simsum = simsum + model.similarity(word,genre)\n",
    "                    n = n + 1\n",
    "                except:\n",
    "                    continue\n",
    "            if n!=0:\n",
    "                gscore.append((simsum)/n)\n",
    "            else:\n",
    "                gscore.append(0)\n",
    "        scores.append(gscore)\n",
    "    else:\n",
    "        scores.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "editedscores = []\n",
    "for score in scores:\n",
    "    if score is not None:\n",
    "        editedscores.append(score)\n",
    "    else:\n",
    "        editedscores.append([0] * 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scoredf = pd.DataFrame(editedscores,columns = [genre + '_Score' for genre in genres])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "amzbookfeatures = pd.concat([amazonbookfeatures.reset_index(drop=True),scoredf],axis = 1)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py35]",
   "language": "python",
   "name": "Python [py35]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
